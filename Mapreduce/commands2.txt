
hdoop@puneeth-virtual-machine:~$ jps
3940 SecondaryNameNode
4885 NameNode
2394 org.eclipse.equinox.launcher_1.5.600.v20191014-2022.jar
4139 ResourceManager
3740 DataNode
8540 Jps


hdoop@puneeth-virtual-machine:~$ hadoop jar /home/puneeth-virtual-machine/lab81.jar /lab8/input1.txt /output7
2021-05-10 15:51:46,703 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2021-05-10 15:51:47,691 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-05-10 15:51:47,744 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/sath17/.staging/job_1620637533311_0008
2021-05-10 15:51:48,524 INFO input.FileInputFormat: Total input files to process : 1
2021-05-10 15:51:48,787 INFO mapreduce.JobSubmitter: number of splits:1
2021-05-10 15:51:49,344 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1620637533311_0008
2021-05-10 15:51:49,346 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-05-10 15:51:49,988 INFO conf.Configuration: resource-types.xml not found
2021-05-10 15:51:49,989 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-05-10 15:51:50,183 INFO impl.YarnClientImpl: Submitted application application_1620637533311_0008
2021-05-10 15:51:50,439 INFO mapreduce.Job: The url to track the job: http://gagan:8088/proxy/application_1620637533311_0008/
2021-05-10 15:51:50,440 INFO mapreduce.Job: Running job: job_1620637533311_0008
2021-05-10 15:52:03,908 INFO mapreduce.Job: Job job_1620637533311_0008 running in uber mode : false
2021-05-10 15:52:03,911 INFO mapreduce.Job:  map 0% reduce 0%
2021-05-10 15:52:12,183 INFO mapreduce.Job:  map 100% reduce 0%
2021-05-10 15:52:21,352 INFO mapreduce.Job:  map 100% reduce 100%
2021-05-10 15:52:22,481 INFO mapreduce.Job: Job job_1620637533311_0008 completed successfully
2021-05-10 15:52:22,852 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=51
		FILE: Number of bytes written=469529
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=632
		HDFS: Number of bytes written=13
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5873
		Total time spent by all reduces in occupied slots (ms)=6220
		Total time spent by all map tasks (ms)=5873
		Total time spent by all reduce tasks (ms)=6220
		Total vcore-milliseconds taken by all map tasks=5873
		Total vcore-milliseconds taken by all reduce tasks=6220
		Total megabyte-milliseconds taken by all map tasks=6013952
		Total megabyte-milliseconds taken by all reduce tasks=6369280
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=35
		Map output materialized bytes=51
		Input split bytes=102
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=51
		Reduce input records=5
		Reduce output records=2
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=159
		CPU time spent (ms)=1470
		Physical memory (bytes) snapshot=418258944
		Virtual memory (bytes) snapshot=4968304640
		Total committed heap usage (bytes)=344981504
		Peak Map Physical memory (bytes)=260886528
		Peak Map Virtual memory (bytes)=2479800320
		Peak Reduce Physical memory (bytes)=157442048
		Peak Reduce Virtual memory (bytes)=2488504320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=530
	File Output Format Counters 
		Bytes Written=13


hdoop@puneeth-virtual-machine:~$ hdfs dfs -cat /output7/*
03	111
05	22
hdoop@puneeth-virtual-machine
